from bibliograph.util import df_progress_bar
from datetime import datetime
from os import environ
from pandas import DataFrame
from pandas import Series
from requests import get as http_get
from urllib.parse import quote as urlquote


def make_ads_query(row_to_query, bib_transformers, ads_transformers, wrapper=''):

    if type(row_to_query) is not Series:
        if len(row_to_query) == 1:
            row_to_query = row_to_query.squeeze()
        else:
            raise ValueError('row_to_query must be pd.Series or pd.DataFrame-like object with a squeeze method and exactly one row.')

    if wrapper not in ['', 'references', 'citations']:
        raise ValueError('ADS query wrapper must be in ["", "references", or "citations"]')

    prefix = 'https://api.adsabs.harvard.edu/v1/search/query?q='

    bib_cols = row_to_query.index
    copy_keys = [k for k,v in bib_transformers.items() if (v == 'copy')]
    transform_keys = [k for k in bib_transformers.keys() if k not in copy_keys]

    query_field_data = [bib_transformers[key](row_to_query[key]) for key in transform_keys]
    for key in copy_keys:
        query_field_data.append({key:row_to_query[key]})
    [query_field_data[0].update(d) for d in query_field_data[1:]]
    query_field_data = query_field_data[0]
    query_text = '+'.join([(str(k) + ':' + str(v)) for k,v in query_field_data.items()])
    if wrapper != '':
        query_text = wrapper + '(' + query_text + ')'

    fetch_terms = '+'.join(ads_transformers.keys())
    query_text = query_text + '&fl=' + fetch_terms

    return prefix + query_text


def submit_ads_query(ads_query, key=None):
    if key is None:
        try:
            key = os.environ['ADS_DEV_KEY']
        except KeyError:
            error_text = 'Cannot find ADS developer key to access API.\n'
            error_text += 'Directions here: https://github.com/adsabs/adsabs-dev-api#access\n'
            error_text += 'Either pass the key as a variable to submit_ads_query or create an environment variable called "ADS_DEV_KEY"'
            raise KeyError(error_text)

    r = http_get(ads_query, headers={'Authorization':'Bearer ' + key})

    return r


def parse_ads_response(ads_response, ads_transformers):
    if 'bibcode' not in ads_transformers.keys():
        ads_transformers['bibcode'] = 'copy'

    response_json = ads_response.json()
    fetched_docs = response_json['response']['docs']
    num_found = response_json['response']['numFound']

    if num_found == 0:
        return Series({}, dtype='object')
    elif num_found > 1:
        bibcodes = ' '.join([doc['bibcode'] for doc in fetched_docs])
        new_row = {'bibcode':bibcodes}
        return Series(new_row)
    elif num_found == 1:
        copy_keys = [k for k,v in ads_transformers.items() if (v == 'copy')]
        transform_keys = [k for k in ads_transformers.keys() if k not in copy_keys]
        fetched_data = fetched_docs[0]
        new_row = [ads_transformers[k](fetched_data[k]) for k in transform_keys]
        [new_row[0].update(d) for d in new_row[1:]]
        new_row = new_row[0]
        for k in copy_keys:
            new_row[k] = fetched_data[k]
        return Series(new_row)


def make_query(this_src, queries, search_cols, search_dict, wrapper):

    query = []
    if search_dict is None:
        search_dict = dict(zip(search_cols, search_cols))

    for c in search_cols:
        value = str(this_src[c])
        if (' ' not in value) and (value != 'x'):
            if c == 'doi':
                query.append('doi:' + urlquote(value, safe=''))
            else:
                query.append(search_dict[c] + ':' + value)

    if len(query) == 0:
        queries.loc[this_src.name] = 'x'
    else:
        query = ' '.join(query)
        if wrapper is not None:
            query = wrapper + '(' + query + ')'
        queries.loc[this_src.name] = query

def make_queries(sources, search_cols, search_dict=None, query_mask=None, wrapper=None):
    '''
    Make strings that represent ADS search queries

    Parameters
    ----------
    sources : pd.DataFrame
        Papers for which data will be found on NASA/ADS.

    search_cols : list-like
        Column labels in the sources DataFrame which contain data for
        the ADS search queries.


    search_dict:


    query_mask : pd.DataFrame, dtype == boolean
        A boolean mask to select which sources should be queried.

    wrapper : string
        An ADS operator to wrap the query string, such as
        'references'. List of ADS operators is in the drop-down menu
        above the search bar at https://ui.adsabs.harvard.edu/

    Returns
    -------
    queries : pd.DataFrame
        pandas DataFrame with query strings whose index corresponds to
        the index of the correpsonding papers in the sources DataFrame

    bad_queries : list
        List of index values from the sources DataFrame for which
        values in columns to be searched either contained spaces or
        were 'x'.
    '''

    if search_dict is not None:
        ads_search_terms = [search_dict[c] for c in search_cols]

    if query_mask is not None:
        sources = sources[query_mask]

    queries = DataFrame(columns=['qstr'], index=sources.index)
    sources.apply(lambda x: make_query(x, queries, search_cols, search_dict, wrapper), axis=1)

    return(queries)

def old_parse_ads_response(r_json, fetch_dict, article_processor):
    documents = r_json['response']['docs']
    numFound = r_json['response']['numFound']

    if numFound == 0:
        return({})
    else:
        new_data = {}
        doc = documents[0]
        for k,v in fetch_dict.items():
            try:
                new_data[v] = article_processor(k, art[k])
            except KeyError:
                new_data[v] = 'x'

    if numFound > 1:
        for doc in documents[1:]:
            for k,v in fetch_dict.items():
                try:
                    new_data[v] = new_data[v] + ' ' + article_processor(k, art[k])
                except KeyError:
                    new_data[v] = new_data[v] + ' x'

    return(new_data)

def confirm_ads_submission(queries):
    # can't get ratelimits from ADS API as of 7 Jan 2021, so this is a dummy
    return True

def submit_ads_queries(this_q, queries, results, fetch_cols, ads_fetch_terms, article_processor):

    print(ads_fetch_terms)
    search = ads.SearchQuery(q=this_q['qstr'], fl=ads_fetch_terms)
    try:
        print('submitted query "' + this_q['qstr'] + '"')
        search.execute()
    finally:
        results.to_json('results.json')
        queries.to_json('queries.json')
    this_q['ADSarticles'] = search.articles
    fetched = [(article_processor(art) + [this_q.name]) for art in search.articles]
    results = results.append(Series(dict(zip(fetch_cols, fetched))), ignore_index=True)
    df_progress_bar(len(queries), this_q.name)
